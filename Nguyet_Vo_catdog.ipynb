{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Nguyet Vo_catdog.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyetvo/cat_dog_classification/blob/master/Nguyet_Vo_catdog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RopAG5ZaGLLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 -m pip install tensorflow-gpu==2.0.0 --user "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI4C0WctbQCL",
        "colab_type": "text"
      },
      "source": [
        "# **Cat & Dog Classification with Tensorflow**\n",
        "This notebook explores tensorflow to classify a dataset of 25,000 dogs & cats images. It will go through the processes of loading and preparing data, defining the model to train data, and training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTKkSnNYbbI8",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Libraries & Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ez1Ak_IO_nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade \"tensorflow==1.4\" \"keras>=2.0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_D1ery4GSgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import libaries\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf \n",
        "import os \n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_a8P8hKGpIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpd-KN61Grjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwpxF8cRGtgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"nguyetvo\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"1f34732ea5c843e829d5230feff0e412\" # key from the json file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjP11B2uGxTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AGBXMOIG2_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip dogs-vs-cats.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7P9UeHyG7bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train.zip\n",
        "!unzip test1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilQ1keDJG-KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to train & test data\n",
        "\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test1/'\n",
        "\n",
        "# All image paths \n",
        "train_data_path = [train_dir + file_name for file_name in os.listdir(train_dir)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_nvHGkHI5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir(train_dir)[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtc-RvCSbocA",
        "colab_type": "text"
      },
      "source": [
        "**Load and Preprocess Data**\n",
        "\n",
        "This dataset consists of 25,000 images of cats and dogs split equally and in jpeg format.\n",
        "\n",
        "To process the images, let's apply a few functions from the tensorflow image module. \n",
        "1.  **tf.image.decode_jpeg**\n",
        "- From the module tf.image, the decode_jpeg function decodes a JPEG-encoded image to a uint8 tensor. In our implementation, I input the arguments image as contents and channels with the value 3 which indicates the number of color channels for the decoded image. \n",
        "2.  **tf.image.resize** \n",
        "- From the same module, I employ resize which per its name - resizes images to a specific size using the specified method. \n",
        "3. **Normalization**\n",
        "- Lastly, I divide the image by 255 to normalize the image to range 0 to 1. Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution </font>. This makes convergence faster while training the network.\n",
        "4. To load the images from their paths, let's use **read_file** from the tensorflow io module which reads and outputs the entire contents of the input filename.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHVg9h5lHLK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 299\n",
        "\n",
        "'''\n",
        "FIRST, I DEFINE A FUCNTION WHERE APPLY TENSORFLOW FUNCTIONS ARE APPLIED TO PROCESS RAW IMAGES.\n",
        "'''\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    #decode image into tensors\n",
        "    image = tf.image.decode_jpeg(image, channels = 3) \n",
        "    \n",
        "    #resize image to fit with Xception's required input\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE]) \n",
        "    \n",
        "    #normalize pixels to range (0, 1)\n",
        "    image /= 255.0 \n",
        "\n",
        "    #return preprocessed images\n",
        "    return image\n",
        "\n",
        "'''\n",
        "NOW, LET'S DEFINE A FUNCTION TO LOAD IMAGES FROM IMAGE PATHS, \n",
        "APPLY PREPROCESSING AND RETURN PREPROCESSED IMAGES. \n",
        "'''\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOjxVZ34dVur",
        "colab_type": "text"
      },
      "source": [
        "**Next, let's employ another one of  tensorflow modules - data.**\n",
        "\n",
        "**tf.data.Dataset.from_tensor_slices( )** method, I can get the slices of an array in the form of objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VmpU0SvHOV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' \n",
        "FROM IMAGE PATHS (train_data_path), \n",
        "SLICE individual path\n",
        "'''\n",
        "path_dataset = tf.data.Dataset.from_tensor_slices(train_data_path)\n",
        "\n",
        "# Create image dataset from path dataset\n",
        "image_dataset = path_dataset.map(load_and_preprocess_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcLyqWnHQil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_path[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PPkKz_bHTEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(train_data_path))\n",
        "print(type(path_dataset))\n",
        "print(type(image_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LFOOZcxd2-l",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is 'labelled' such that the name of the file contains 'dog' or 'cat' . \n",
        "\n",
        "I assign 1 to file name containing 'cat', 0 for file name containing 'dog'. Let's save this in image_label.\n",
        "\n",
        "Using tf.cast, I change image_label datatype to int64 before applying from_tensor_slices on the labels and save it in another variable called label_dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB-civDUHV20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "I ASSIGN THE IMAGE LABEL WITH 1 IF ITS FILE NAME CONTAINS 'CAT'\n",
        "BINARILY, FILE NAMES CONTAINING 'DOG' WILL BE ASSIGNED WITH 0.\n",
        "'''\n",
        "\n",
        "image_label = list(map(lambda x: 1 if 'cat' in x else 0, os.listdir(train_dir)))\n",
        "\n",
        "'''\n",
        "NEXT, I USE TF.CAST TO CHANGE THE DATA TYPE TO INT64 BEFORE SLICING.\n",
        "'''\n",
        "label_dataset = tf.data.Dataset.from_tensor_slices(tf.cast(image_label, tf.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjBNQH-GeNQ2",
        "colab_type": "text"
      },
      "source": [
        "Before splitting up the dataset into three separate sets <font color = gray> Training, Validation & Testing </font>, let's <font color = red> zip </font> the images and their respective labels together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kzbmhj6HYIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine image dataset and image label dataset\n",
        "\n",
        "dataset = tf.data.Dataset.zip((image_dataset, label_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMKST9pYHaK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDDaY1QfeTwz",
        "colab_type": "text"
      },
      "source": [
        "**Split**\n",
        "\n",
        "Train : Validation : Test = 70 : 15 : 15.\n",
        "\n",
        "**Train Set**\n",
        "\n",
        "- To get the 70% of data for the train set, we define train_size to be 70% of dataset_size.\n",
        "- Next, I apply shuffle to tf.data.Dataset.zip((image_dataset, label_dataset)) or our earlier defined dataset using shuffle_buffer_size of 4096. This will split the dataset into batches of 4096 images, then shuffling each batch before placing them back into the population. The smaller the shuffle_buffer_size, the more randomized the population will end up.\n",
        "- Then, the train_dataset will be defined by applying take using the train_size (70% * 25,000). It takes grab the first 70% of the images after shuffling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCwRLaqcHb_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_SIZE = 25000\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_BUFFER_SIZE = 4096\n",
        "\n",
        "train_size = int(0.7 * DATASET_SIZE)\n",
        "val_size = int(0.15 * DATASET_SIZE)\n",
        "test_size = int(0.15 * DATASET_SIZE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size = SHUFFLE_BUFFER_SIZE)\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)\n",
        "val_dataset = test_dataset.skip(val_size)\n",
        "test_dataset = test_dataset.take(test_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz6SLq-XfQiq",
        "colab_type": "text"
      },
      "source": [
        "Let's perform mini-batching onto the <font color = gray> train_dataset</font> & <font color = gray> test_dataset </font> then save them again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlOQhpS6HeKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform mini-batch in train_dataset and test_dataset\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, \n",
        "                                                                 drop_remainder = True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KojvQkZafWbG",
        "colab_type": "text"
      },
      "source": [
        "**Building the Model.**\n",
        "\n",
        "- In this notebook, I employ a pretrained model Xception. Xception is a convolutional neural network that is trained on more than a million images from the ImageNet database. The network is 71 layers deep and can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals.\n",
        "As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 299-by-299."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olxu1NAfHgG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "def define_model():\n",
        "    # load model\n",
        "    pretrained_model = tf.keras.applications.Xception(include_top = False, input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    \n",
        "    # mark pretrained layers as not trainable\n",
        "    pretrained_model.trainable = False\n",
        "    \n",
        "    # add new classifier layers\n",
        "    model = tf.keras.Sequential([pretrained_model,\n",
        "                                 tf.keras.layers.Flatten(),\n",
        "                                 tf.keras.layers.Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'),\n",
        "                                 tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr = 0.001, momentum = 0.9)\n",
        "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = define_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Xw6eS0frGu",
        "colab_type": "text"
      },
      "source": [
        "**Callbacks**\n",
        "\n",
        "Callbacks are utilities called at certain points during training. In this notebook, I employ two callbacks:\n",
        "\n",
        "1. ReduceLROnPlateau to reduce the learning rate by a factor of 0.1 if val_loss does not improve after 3 epochs. (patience = 3). The min_lr specifies the minimum learning rate to be 0.00001. verbose simply shows the progress.\n",
        "2. ModelCheckpoint with the param save_best_only = True will saves the model in the file checkpoint.h5 at the epoch with the best results (accuracy, val_loss, val_accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k729HRbQHhqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callbacks\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.training.adam import AdamOptimizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#!pip install --upgrade \"tensorflow==1.4\" \"keras>=2.0\"\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.ReduceLROnPlateau()\n",
        "\n",
        "callbacks = [ReduceLROnPlateau(factor = 0.1, patience = 3, min_lr = 0.00001, verbose = 1),\n",
        "             ModelCheckpoint('model_design.h5', verbose = 1, save_best_only = True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px9qf4biHkXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "model_history = model.fit(train_dataset, \n",
        "                          epochs = 5, \n",
        "                          validation_data = val_dataset, \n",
        "                          callbacks = callbacks) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtyyeXohH2Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy = model_history.history['accuracy']\n",
        "validation_accuracy = model_history.history['val_accuracy']\n",
        "\n",
        "train_loss = model_history.history['loss']\n",
        "validation_loss = model_history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(train_accuracy, label='Training')\n",
        "plt.plot(validation_accuracy, label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_loss, label='Training')\n",
        "plt.plot(validation_loss, label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.title('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HaMc5mFIzJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model\n",
        "final_model = tf.keras.models.load_model('model_design.h5')\n",
        "final_model.evaluate(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}